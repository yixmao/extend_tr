{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c2eb96-b62f-416b-b2bf-3c1727016806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from extendtr.TR.topoReg import TopoReg\n",
    "from extendtr.utils.args import TopoRegArgs\n",
    "from extendtr.utils.utils import set_seed, metric_calc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e00d16",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be6abcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the descriptor - the indices of desc will be used later\n",
    "desc = pd.read_parquet(f'./SampleDatasets/CHEMBL278/data_ECFP4.parquet', engine='fastparquet').astype('bool')\n",
    "# load targets\n",
    "data = pd.read_csv(f'./SampleDatasets/CHEMBL278/data_cp.csv', index_col=0)\n",
    "target = data[\"pChEMBL Value\"]\n",
    "# make sure that the indices of desc and target match\n",
    "desc = desc.loc[target.index]\n",
    "target = target.loc[desc.index]\n",
    "\n",
    "# load indicies for scaffold split\n",
    "with open(f'./SampleDatasets/CHEMBL278/scaffold_split_index.json', 'r') as f:\n",
    "    index = json.load(f)  \n",
    "train_idx = index['train_idx']\n",
    "test_idx = index['test_idx']\n",
    "# make sure that train and test indices are included in target.index\n",
    "train_idx = [idx for idx in train_idx if idx in target.index]\n",
    "test_idx = [idx for idx in test_idx if idx in target.index]\n",
    "\n",
    "##### alternatively, you can ranomly split train and test idx\n",
    "# dataset_idx = target.index.tolist()\n",
    "# train_idx, test_idx = train_test_split(dataset_idx, test_size=0.2, random_state=args.seed)\n",
    "\n",
    "# set validation index if necessary\n",
    "val_set = 0.2 # a fraction number to use [val_set] percent samples from the train set as val set, or None for no validation\n",
    "if val_set is not None: # if we want to test on the validation set\n",
    "    train_idx, val_idx = train_test_split(train_idx, test_size=val_set, random_state=2021)\n",
    "else: # no validation\n",
    "    val_idx = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a248f8e",
   "metadata": {},
   "source": [
    "## Run ensemble TR with ECFP4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3379ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the args\n",
    "args = TopoRegArgs('-ensemble 1') # ensemble TR\n",
    "# set random seed\n",
    "set_seed(args.seed)\n",
    "\n",
    "# train and get the predictions\n",
    "mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, val_idx, args)\n",
    "\n",
    "# evaluate the resuls\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe130fb",
   "metadata": {},
   "source": [
    "## Run ensemble TR with ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c54d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the args\n",
    "args = TopoRegArgs('-ensemble 1 -distance jaccard -model ANN -val_set 0.2 -ann_cp_dir ./results/ann_cp/') # ensemble TR, Jaccard distance, ANN model, 0.2 validation set, dir to save the checkpoints\n",
    "# set random seed\n",
    "set_seed(args.seed)\n",
    "# train and get the predictions\n",
    "mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, args)\n",
    "# evaluate the resuls\n",
    "args.verbose = 1 # to report the metrics\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1a3ef",
   "metadata": {},
   "source": [
    "## Run Mordred descriptor with Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cedf591",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc = pd.read_parquet(f'./SampleDatasets/CHEMBL278/data_Mordred.parquet', engine='fastparquet')\n",
    "desc = desc.loc[target.index]\n",
    "# get the args\n",
    "args = TopoRegArgs('-ensemble 1 -distance euclidean -desc_norm 1') # ensemble TR, euclidean distance, normalize the descriptors before calculate the distances\n",
    "# set random seed\n",
    "set_seed(args.seed)\n",
    "\n",
    "# train and get the predictions\n",
    "mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, args)\n",
    "\n",
    "# evaluate the resuls\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37af93a1",
   "metadata": {},
   "source": [
    "## Combine predictions from various configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5154039",
   "metadata": {},
   "source": [
    "### prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81b66cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the descriptor - the indices of desc will be used later\n",
    "desc = pd.read_parquet(f'./SampleDatasets/CHEMBL278/data_ECFP4.parquet', engine='fastparquet').astype('bool')\n",
    "# load targets\n",
    "data = pd.read_csv(f'./SampleDatasets/CHEMBL278/data_cp.csv', index_col=0)\n",
    "target = data[\"pChEMBL Value\"]\n",
    "# make sure that the indices of desc and target match\n",
    "desc = desc.loc[target.index]\n",
    "target = target.loc[desc.index]\n",
    "\n",
    "# load indicies for scaffold split\n",
    "with open(f'./SampleDatasets/CHEMBL278/scaffold_split_index.json', 'r') as f:\n",
    "    index = json.load(f)  \n",
    "train_idx = index['train_idx']\n",
    "test_idx = index['test_idx']\n",
    "# make sure that train and test indices are included in target.index\n",
    "train_idx = [idx for idx in train_idx if idx in target.index]\n",
    "test_idx = [idx for idx in test_idx if idx in target.index]\n",
    "\n",
    "##### alternatively, you can ranomly split train and test idx\n",
    "# dataset_idx = target.index.tolist()\n",
    "# train_idx, test_idx = train_test_split(dataset_idx, test_size=0.2, random_state=args.seed)\n",
    "\n",
    "# set validation index if necessary\n",
    "val_set = 0.2 # a fraction number to use [val_set] percent samples from the train set as val set, or None for no validation\n",
    "if val_set is not None: # if we want to test on the validation set\n",
    "    train_idx, val_idx = train_test_split(train_idx, test_size=val_set, random_state=2021)\n",
    "else: # no validation\n",
    "    val_idx = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3160b9a",
   "metadata": {},
   "source": [
    "### Different descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0400a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble predictions:\n",
      "Spearman: 0.8048832322935336\n",
      "R2: 0.8186644222390181\n",
      "RMSE: 0.7897068461943904\n",
      "NRMSE: 0.42583515327058413\n",
      "Performance of stacking predictions:\n",
      "Spearman: 0.7736080001537748\n",
      "R2: 0.8187167121490055\n",
      "RMSE: 0.7895929780894521\n",
      "NRMSE: 0.4257737519516609\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import stack_models\n",
    "# define arg strs for different anchor selection methods\n",
    "args = TopoRegArgs(f'-ensemble 1')\n",
    "descriptors = ['ECFP4', 'ECFP6', 'Mordred', 'RDKdesc', 'tcnn_zpad']\n",
    "data_path = './SampleDatasets/CHEMBL278/'\n",
    "\n",
    "########################### Train and get the prediction ###############################\n",
    "preds_test = []\n",
    "preds_val = []\n",
    "for descriptor in descriptors:\n",
    "    # Load descriptors\n",
    "    if descriptor in ['ECFP4', 'ECFP6']:\n",
    "        desc = pd.read_parquet(f'{data_path}/data_{descriptor}.parquet', engine='fastparquet').astype('bool')\n",
    "    elif descriptor in ['Mordred', 'RDKdesc']:\n",
    "        desc = pd.read_parquet(f'{data_path}/data_{descriptor}.parquet', engine='fastparquet')\n",
    "    elif descriptor == 'tcnn_zpad':\n",
    "        desc = pd.read_csv(f\"{data_path}/tcnn_embeddings_zpad.csv\", index_col=0)\n",
    "    \n",
    "    if descriptor in ['ECFP4', 'ECFP6']:\n",
    "        args.distance = 'jaccard'\n",
    "        args.desc_norm = False\n",
    "    else:\n",
    "        args.distance = 'euclidean'\n",
    "        args.desc_norm = True\n",
    "\n",
    "    # set random seed\n",
    "    set_seed(args.seed)\n",
    "    mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, val_idx, args)\n",
    "    # Stack the predicted responses for test and validation sets\n",
    "    preds_test.append(pred_test)\n",
    "    preds_val.append(pred_val)\n",
    "\n",
    "########################### Combine the results ###############################\n",
    "# ensemble\n",
    "pred_test = np.array(preds_test).mean(axis=0)\n",
    "# evaluation\n",
    "print('Performance of ensemble predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)\n",
    "\n",
    "# stacking the results\n",
    "pred_test, train_time, test_time = stack_models(preds_val, preds_test, target, val_idx)\n",
    "# evaluation\n",
    "print('Performance of stacking predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0ee9b",
   "metadata": {},
   "source": [
    "### Different anchor selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b4cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e-02, tolerance: 1.285e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.311e-02, tolerance: 1.596e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.822e-02, tolerance: 1.069e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.294e-02, tolerance: 1.529e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.718e-02, tolerance: 1.262e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.106e-02, tolerance: 1.911e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.852e-02, tolerance: 1.466e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.428e-02, tolerance: 1.764e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.934e-02, tolerance: 1.339e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.238e-02, tolerance: 1.212e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e-02, tolerance: 1.673e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.910e-02, tolerance: 1.381e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.802e-02, tolerance: 1.718e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e-02, tolerance: 1.429e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.138e-02, tolerance: 1.496e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.498e-02, tolerance: 1.507e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.267e-02, tolerance: 1.548e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.355e-02, tolerance: 1.569e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e-02, tolerance: 1.221e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.178e-01, tolerance: 1.689e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.092e-02, tolerance: 1.921e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.086e-02, tolerance: 1.918e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e-02, tolerance: 1.228e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.209e-02, tolerance: 1.284e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e-01, tolerance: 1.683e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.709e-02, tolerance: 1.405e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.943e-02, tolerance: 1.165e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\y1mao\\anaconda3\\envs\\TopoReg\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e-02, tolerance: 1.032e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates detected, removing...\n",
      "Number of duplicate samples removed: 3\n",
      "Performance of ensemble predictions:\n",
      "Spearman: 0.8280874367843225\n",
      "R2: 0.8694860451159991\n",
      "RMSE: 0.6699661613109632\n",
      "NRMSE: 0.36126715168141277\n",
      "Performance of stacking predictions:\n",
      "Spearman: 0.7875305228482481\n",
      "R2: 0.8355321248736358\n",
      "RMSE: 0.7520815480801967\n",
      "NRMSE: 0.40554639084371624\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import stack_models\n",
    "# load the descriptor - the indices of desc will be used later\n",
    "desc = pd.read_parquet(f'./SampleDatasets/CHEMBL278/data_ECFP4.parquet', engine='fastparquet').astype('bool')\n",
    "# define arg strs for different anchor selection methods\n",
    "arg_strs_anchor = [f'-ensemble 1', \n",
    "                f'-anchorselection maximin -ensemble 1 -mean_anchor_percentage 0.4 -min_anchor_percentage 0.2 -max_anchor_percentage 0.6',\n",
    "                f'-refine_anchors_lasso 1 -anchor_percentage 0.8', \n",
    "                f'-anchorselection maximin_density -weight_density 0.5 -check_duplicates 1'\n",
    "                ]\n",
    "\n",
    "\n",
    "########################### Train and get the prediction ###############################\n",
    "preds_test = []\n",
    "preds_val = []\n",
    "for arg_str in arg_strs_anchor:\n",
    "    args = TopoRegArgs(f'{arg_str}')\n",
    "    # set random seed\n",
    "    set_seed(args.seed)\n",
    "    mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, val_idx, args)\n",
    "    # Stack the predicted responses for test and validation sets\n",
    "    preds_test.append(pred_test)\n",
    "    preds_val.append(pred_val)\n",
    "\n",
    "########################### Combine the results ###############################\n",
    "# ensemble\n",
    "pred_test = np.array(preds_test).mean(axis=0)\n",
    "# evaluation\n",
    "print('Performance of ensemble predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)\n",
    "\n",
    "\n",
    "# stacking the results\n",
    "pred_test, train_time, test_time = stack_models(preds_val, preds_test, target, val_idx)\n",
    "# evaluation\n",
    "print('Performance of stacking predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad777949",
   "metadata": {},
   "source": [
    "### Different distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4b504cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble predictions:\n",
      "Spearman: 0.825262577107183\n",
      "R2: 0.8559141141012051\n",
      "RMSE: 0.7039391402479692\n",
      "NRMSE: 0.3795864669594991\n",
      "Performance of stacking predictions:\n",
      "Spearman: 0.8621875286012207\n",
      "R2: 0.8961914782635478\n",
      "RMSE: 0.5975041088987387\n",
      "NRMSE: 0.3221932987143775\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import stack_models\n",
    "# load the descriptor - the indices of desc will be used later\n",
    "desc = pd.read_parquet(f'./SampleDatasets/CHEMBL278/data_ECFP4.parquet', engine='fastparquet').astype('bool')\n",
    "# define arg strs for different anchor selection methods\n",
    "arg_strs_dist = [f'-ensemble 1', \n",
    "                f'-distance tversky -ensemble 1',\n",
    "                f'-distance euclidean -ensemble 1', \n",
    "                f'-distance cosine -ensemble 1'\n",
    "                ]\n",
    "\n",
    "\n",
    "########################### Train and get the prediction ###############################\n",
    "preds_test = []\n",
    "preds_val = []\n",
    "for arg_str in arg_strs_dist:\n",
    "    args = TopoRegArgs(f'{arg_str}')\n",
    "    # set random seed\n",
    "    set_seed(args.seed)\n",
    "    mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, val_idx, args)\n",
    "    # Stack the predicted responses for test and validation sets\n",
    "    preds_test.append(pred_test)\n",
    "    preds_val.append(pred_val)\n",
    "\n",
    "########################### Combine the results ###############################\n",
    "# ensemble\n",
    "pred_test = np.array(preds_test).mean(axis=0)\n",
    "# evaluation\n",
    "print('Performance of ensemble predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)\n",
    "\n",
    "\n",
    "# stacking the results\n",
    "pred_test, train_time, test_time = stack_models(preds_val, preds_test, target, val_idx)\n",
    "# evaluation\n",
    "print('Performance of stacking predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71afa3fa",
   "metadata": {},
   "source": [
    "### Different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07a3763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of ensemble predictions:\n",
      "Spearman: 0.825262577107183\n",
      "R2: 0.8559141141012051\n",
      "RMSE: 0.7039391402479692\n",
      "NRMSE: 0.3795864669594991\n",
      "Performance of stacking predictions:\n",
      "Spearman: 0.8621875286012207\n",
      "R2: 0.8961914782635478\n",
      "RMSE: 0.5975041088987387\n",
      "NRMSE: 0.3221932987143775\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import stack_models\n",
    "# load the descriptor - the indices of desc will be used later\n",
    "desc = pd.read_parquet(f'./SampleDatasets/CHEMBL278/data_ECFP4.parquet', engine='fastparquet').astype('bool')\n",
    "# define arg strs for different anchor selection methods\n",
    "arg_strs_mdls = [f'-ensemble 1', \n",
    "                f'-model LR_L1 -ensemble 1',\n",
    "                f'-model RF -ensemble 1', \n",
    "                f'-model ANN -ensemble 1'\n",
    "                ]\n",
    "\n",
    "\n",
    "########################### Train and get the prediction ###############################\n",
    "preds_test = []\n",
    "preds_val = []\n",
    "for arg_str in arg_strs_dist:\n",
    "    args = TopoRegArgs(f'{arg_str}')\n",
    "    # set random seed\n",
    "    set_seed(args.seed)\n",
    "    mdl, pred_test, pred_val, train_time, test_time = TopoReg(desc, target, train_idx, test_idx, val_idx, args)\n",
    "    # Stack the predicted responses for test and validation sets\n",
    "    preds_test.append(pred_test)\n",
    "    preds_val.append(pred_val)\n",
    "\n",
    "########################### Combine the results ###############################\n",
    "# ensemble\n",
    "pred_test = np.array(preds_test).mean(axis=0)\n",
    "# evaluation\n",
    "print('Performance of ensemble predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)\n",
    "\n",
    "\n",
    "# stacking the results\n",
    "pred_test, train_time, test_time = stack_models(preds_val, preds_test, target, val_idx)\n",
    "# evaluation\n",
    "print('Performance of stacking predictions:')\n",
    "scorr, r2, rmse, nrmse = metric_calc(pred_test, target.loc[test_idx], True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TopoReg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
